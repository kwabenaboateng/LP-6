{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MrDadzie/Sepsis_Classification_Project/blob/master/Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1Jb-FGnXfTS"
   },
   "source": [
    "# Intro\n",
    "## General\n",
    "\n",
    "In this project, the CRISP-DM approach is explored to analyse a patient dataset and build several machine learning models to predict whether a patient will be diagnosed as Sepsis or not. The best model is exported and deployed as a web app using a FAST API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfjyKYSSX-AT"
   },
   "source": [
    "#Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zVjAvcvnGgX"
   },
   "source": [
    "#Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VVKGiVbXMua",
    "outputId": "b4bf1d12-2a3a-4b18-8807-f3065a490f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas_profiling in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: joblib~=1.1.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (1.10.0)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (3.6.3)\n",
      "Requirement already satisfied: pydantic>=1.8.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (1.10.9)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (6.0)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.1.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (2.1.1)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.4 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (1.24.1)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (0.1.12)\n",
      "Requirement already satisfied: missingno>=0.4.2 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (0.5.2)\n",
      "Requirement already satisfied: phik>=0.11.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (0.12.3)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.2.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (4.65.0)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (0.12.2)\n",
      "Requirement already satisfied: multimethod>=1.4 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas_profiling) (1.9.1)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (22.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (3.1)\n",
      "Requirement already satisfied: imagehash in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (4.3.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (22.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas_profiling) (2022.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.8.1->pandas_profiling) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.48.2->pandas_profiling) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.0->pandas_profiling) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.4->pandas_profiling) (1.4.1)\n",
      "Requirement already satisfied: shap in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.42.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.24.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (4.65.0)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (22.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: numba in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (0.57.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba->shap) (0.40.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->shap) (2022.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->shap) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install pandas_profiling\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYXg5Ta-nONC"
   },
   "source": [
    "#Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "om1hjtoUnSIG",
    "outputId": "752c0bb8-6ba6-4330-81ff-ee95676b21ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KWABENABOATENG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\core\\decorators.py:262: NumbaDeprecationWarning: \u001b[1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\u001b[0m\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n",
      "C:\\Users\\KWABENABOATENG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\visions\\backends\\shared\\nan_handling.py:50: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @nb.jit\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataError' from 'pandas.core.base' (C:\\Users\\KWABENABOATENG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# EDA (pandas-profiling, etc. )\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Feature Processing (Scikit-learn processing, etc. )\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas_profiling\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Main module of pandas-profiling.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m.. include:: ../../README.md\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontroller\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pandas_decorator\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofile_report\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas_profiling\\controller\\pandas_decorator.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This file add the decorator on the DataFrame object.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofile_report\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprofile_report\u001b[39m(df: DataFrame, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ProfileReport:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124;03m\"\"\"Profile a DataFrame.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m        A ProfileReport of the DataFrame.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas_profiling\\profile_report.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, Settings\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpectations_report\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExpectationsReport\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malerts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlertType\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdescribe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m describe \u001b[38;5;28;01mas\u001b[39;00m describe_df\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msample\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sample\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas_profiling\\model\\alerts.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorrelations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m perform_check_correlation\n\u001b[0;32m     13\u001b[0m \u001b[38;5;129m@unique\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAlertType\u001b[39;00m(Enum):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124;03m\"\"\"Alert types\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas_profiling\\model\\correlations.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultimethod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multimethod\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataError\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorrelation\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DataError' from 'pandas.core.base' (C:\\Users\\KWABENABOATENG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py)"
     ]
    }
   ],
   "source": [
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Vizualisation (Matplotlib, Plotly, Seaborn, etc. )\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# EDA (pandas-profiling, etc. )\n",
    "from pandas_profiling import ProfileReport\n",
    "from IPython.display import display\n",
    "\n",
    "# Feature Processing (Scikit-learn processing, etc. )\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import skew\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Machine Learning (Scikit-learn Estimators, Catboost, LightGBM, etc. )\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, fbeta_score, accuracy_score, roc_auc_score\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Hyperparameters Fine-tuning (Scikit-learn hp search, cross-validation, etc. )\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Other packages\n",
    "import pickle\n",
    "from joblib import dump\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NV78myFLpf85"
   },
   "source": [
    "#Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORVwoPn5pjS6"
   },
   "outputs": [],
   "source": [
    "train_data_url = 'https://raw.githubusercontent.com/MrDadzie/Sepsis_Classification_Project/master/Datasets/Patients_Files_Train.csv'\n",
    "test_data_url = 'https://raw.githubusercontent.com/MrDadzie/Sepsis_Classification_Project/master/Datasets/Patients_Files_Test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwG2SOf3qV4z"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_url)\n",
    "test_df = pd.read_csv(test_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEPdbS1jtPm9",
    "outputId": "72d884e0-23a1-49b7-9ba7-beccb69ac5df"
   },
   "outputs": [],
   "source": [
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-nukmdgtK2p"
   },
   "source": [
    "#Exploratory Data Analysis : EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZZHgQdcxGI0"
   },
   "source": [
    "##Renaming Columns\n",
    "Here, the columns are renamed to help in understanding the fields in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28PUvbpvxDrw"
   },
   "outputs": [],
   "source": [
    "new_column_names = {'PRG':'Plasma_Glucose',\n",
    "               'PL': 'Blood_Work_Result1',\n",
    "               'PR': 'Blood_Pressure',\n",
    "               'SK': 'Blood_Work_Result2',\n",
    "               'TS': 'Blood_Work_Result3',\n",
    "               'M11': 'Body_mass_index',\n",
    "               'BD2': 'Blood_Work_Result4'\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "train_df.rename(columns = new_column_names, inplace = True)\n",
    "test_df.rename (columns = new_column_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMcyL7CCNXxC",
    "outputId": "8e0d2665-064b-4011-8e5a-c7dbc17b7844"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrhsvoDV69wP"
   },
   "source": [
    "##Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dk6Neng90ruS",
    "outputId": "7b67d061-0a6f-4842-caac-87abcbb17b96"
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "VJSfIYOP7DpO",
    "outputId": "3f0590ce-9a72-40de-9255-534ce0d722d1"
   },
   "outputs": [],
   "source": [
    "train_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy5xXoME088F"
   },
   "source": [
    "##Hypothesis\n",
    "\n",
    "**Null Hypothesis**: There is no significant difference in the likelihood of young and old patients developing sepssis.\n",
    "\n",
    "**Alternate Hypothesis** : The likelihood of young patients developing sepssis differs significantly from that of old patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzwDqcwS9V9t"
   },
   "source": [
    "####Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpqinsIm5lkX"
   },
   "outputs": [],
   "source": [
    "#Older patients > 40\n",
    "Older_pos = train_df[(train_df['Age']> 40) & (train_df['Sepssis']=='Positive')]\n",
    "Older_neg = train_df[(train_df['Age']> 40) & (train_df['Sepssis']=='Negative')]\n",
    "Old = [len(Older_pos), len(Older_neg)]\n",
    "\n",
    "#Younger patients < 40\n",
    "Young_pos = train_df[(train_df['Age']< 40) & (train_df['Sepssis']=='Positive')]\n",
    "Young_neg = train_df[(train_df['Age']< 40) & (train_df['Sepssis']=='Negative')]\n",
    "Young = [len(Young_pos), len(Young_neg)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIW2vEhJ7lsy",
    "outputId": "d9f05c5a-96ea-4456-cf45-40e0c5fe32de"
   },
   "outputs": [],
   "source": [
    "#Creating  contingency table\n",
    "observed = np.array([Young, Old])\n",
    "\n",
    "#Using the Chi-square test\n",
    "chi2_stat, p_value, dof, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "#Results\n",
    "alpha = 0.05\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(\"Contingency table of expected frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in the likelihood of young and old patients developing sepsis.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the likelihood of young and old patients developing sepsis.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrbspABQFZga"
   },
   "source": [
    "#Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-Jnr45c9b6a",
    "outputId": "2c9d2307-62b0-4289-f06f-74c0e5176104"
   },
   "outputs": [],
   "source": [
    "train_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoGFYjmIIVvW"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VLYMKdi1FyxQ",
    "outputId": "c9763fc4-1716-43b9-c507-cb8d8a67500d"
   },
   "outputs": [],
   "source": [
    "col_names  = train_df.iloc[:,:-2].select_dtypes(include= np.number).columns\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "C9me1ZkqUO25",
    "outputId": "f4362e29-cc6a-433d-b796-ec6edeccf11e"
   },
   "outputs": [],
   "source": [
    "#Visualizing the distribution of the numerical columns using the KDE plot\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(8, 8))  # 2x4 grid\n",
    "\n",
    "for i, col in enumerate(col_names):\n",
    "    row_index = i // 2  # Calculate row index\n",
    "    col_index = i % 2  # Calculate column index\n",
    "\n",
    "    sns.kdeplot(data=train_df, x=col, ax=axes[row_index, col_index], fill=True)\n",
    "    axes[row_index, col_index].set_title(f'Distribution of {col}')\n",
    "    axes[row_index, col_index].set_xlabel(col)\n",
    "    axes[row_index, col_index].set_ylabel('Density')\n",
    "\n",
    "    mean_val = train_df[col].mean()\n",
    "    skewness_val = train_df[col].skew()\n",
    "    kurtosis_val = train_df[col].kurtosis()\n",
    "\n",
    "    axes[row_index, col_index].text(0.6, 0.9, f'Mean: {mean_val:.2f}', transform=axes[row_index, col_index].transAxes)\n",
    "    axes[row_index, col_index].text(0.6, 0.8, f'Skewness: {skewness_val:.2f}', transform=axes[row_index, col_index].transAxes)\n",
    "    axes[row_index, col_index].text(0.6, 0.7, f'Kurtosis: {kurtosis_val:.2f}', transform=axes[row_index, col_index].transAxes)\n",
    "\n",
    "    axes[row_index, col_index].axvline(mean_val, color='blue', linestyle='--', label='Mean')\n",
    "\n",
    "    outliers = train_df[(train_df[col] > mean_val + 3 * train_df[col].std()) | (train_df[col] < mean_val - 3 * train_df[col].std())]\n",
    "    axes[row_index, col_index].plot(outliers[col], [0] * len(outliers), 'ro', label='Potential Outliers')\n",
    "\n",
    "    axes[row_index, col_index].legend(loc = \"center left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-vq7EgMfAI1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoWOw1W1eDiy"
   },
   "source": [
    "Insights:\n",
    "\n",
    "\n",
    "*   List\n",
    "*   List item\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzV8ACd1inYV"
   },
   "source": [
    "## Bivariate & Multivariate Analysis\n",
    "Here is the section to explore, analyze, visualize each variable in relation to the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SsF7fANfhPsF",
    "outputId": "53b07908-f210-4772-a2f5-8d618d537326"
   },
   "outputs": [],
   "source": [
    "# Visualizing the distribution of the variables with respect to the target variable\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12, 12))  # 2x4 grid\n",
    "\n",
    "# Defining the custom color palettes\n",
    "color_palette = ['#c7e9ff', '#a1d4ff', '#7ac0ff', '#55abff', '#3296ff']\n",
    "\n",
    "for i, col in enumerate(col_names):\n",
    "    row_index = i // 2  # Calculate row index\n",
    "    col_index = i % 2  # Calculate column index\n",
    "\n",
    "    sns.violinplot(data=train_df, x='Sepssis', y=col, ax=axes[row_index, col_index], palette=color_palette)\n",
    "    axes[row_index, col_index].set_xlabel('Sepssis')  # Setting xlabel for the specific subplot\n",
    "    axes[row_index, col_index].set_ylabel(col)\n",
    "    axes[row_index, col_index].set_title(f'{col} Distribution by Sepssis')\n",
    "\n",
    "    # Calculate statistics\n",
    "    positive_vals = train_df[train_df['Sepssis'] == 'Positive'][col]\n",
    "    negative_vals = train_df[train_df['Sepssis'] == 'Negative'][col]\n",
    "    stat_dict = {\n",
    "        'Positive': {\n",
    "            'Mean': np.mean(positive_vals),\n",
    "            'Median': np.median(positive_vals),\n",
    "            '25th Percentile': np.percentile(positive_vals, 25),\n",
    "            '75th Percentile': np.percentile(positive_vals, 75)\n",
    "        },\n",
    "        'Negative': {\n",
    "            'Mean': np.mean(negative_vals),\n",
    "            'Median': np.median(negative_vals),\n",
    "            '25th Percentile': np.percentile(negative_vals, 25),\n",
    "            '75th Percentile': np.percentile(negative_vals, 75)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Add statistics as text annotations\n",
    "    axes[row_index, col_index].text(0.3, 0.6, f\"Positive:\\nMean: {stat_dict['Positive']['Mean']:.2f}\\nMedian: {stat_dict['Positive']['Median']:.2f}\\n25th Percentile: {stat_dict['Positive']['25th Percentile']:.2f}\\n75th Percentile: {stat_dict['Positive']['75th Percentile']:.2f}\", transform=axes[row_index, col_index].transAxes, color='black',fontsize = 8)\n",
    "    axes[row_index, col_index].text(0.5, 0.6, f\"Negative:\\nMean: {stat_dict['Negative']['Mean']:.2f}\\nMedian: {stat_dict['Negative']['Median']:.2f}\\n25th Percentile: {stat_dict['Negative']['25th Percentile']:.2f}\\n75th Percentile: {stat_dict['Negative']['75th Percentile']:.2f}\", transform=axes[row_index, col_index].transAxes, color='black', fontsize = 8)\n",
    "\n",
    "# Adjust layout and display plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "ZPH6K1psnL5C",
    "outputId": "cde37986-6dd4-4057-9f30-5b5794ecc383"
   },
   "outputs": [],
   "source": [
    "# Visualizing the correlation between the  numerical features\n",
    "corr_matrix = train_df.iloc[:,:-2].corr()\n",
    "\n",
    "#Generating heatmap for the correlation matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(data=corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOTXOJ5Kn0Pg"
   },
   "source": [
    "\n",
    "* Plasma Glucose of patients shows a relatively stronger positive correlation with the age of the patients.\n",
    "* Beyond this, all features show a weak correlation with each other.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "VM6sqAGPoTD0",
    "outputId": "49956b3c-56e6-4d43-b308-6e84fd014f46"
   },
   "outputs": [],
   "source": [
    "# Categorical Variables - Bar plots\n",
    "categorical_vars = ['Insurance']\n",
    "for var in categorical_vars:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(data=train_df, x=var, hue='Sepssis', palette=color_palette)\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'{var} Distribution by Sepssis')\n",
    "\n",
    "    # Calculate percentage distribution\n",
    "    total = len(train_df['Sepssis'])\n",
    "    percentages = train_df['Sepssis'].value_counts(normalize=True) * 100\n",
    "\n",
    "    # Add data labels and percentage annotations\n",
    "    for p, percentage in zip(plt.gca().patches, percentages):\n",
    "        count = p.get_height()\n",
    "        percentage_label = f'{percentage:.1f}%'\n",
    "        plt.gca().annotate(f'{count}\\n{percentage_label}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KypXEIuGo_B0"
   },
   "source": [
    "# Feature Processing & Engineering\n",
    "Here is the section to **clean**, **process** the dataset and **create new features**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfqWD_W7pSAB"
   },
   "source": [
    "## Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hZw6IgKpCA3",
    "outputId": "22ade503-4403-457f-939a-18683ed80810"
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows in train_df\n",
    "train_duplicate_rows = train_df.duplicated()\n",
    "print(\"Number of duplicate rows in train_df:\", train_duplicate_rows.sum())\n",
    "\n",
    "# Check for duplicate rows in test_df\n",
    "test_duplicate_rows = test_df.duplicated()\n",
    "print(\"Number of duplicate rows in test_df:\", test_duplicate_rows.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jfh5d_wNqKH8"
   },
   "source": [
    "## Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z59FfYPEqK9V",
    "outputId": "ef43563f-f7ce-4746-f6a0-a8b62def3d08"
   },
   "outputs": [],
   "source": [
    "# Use pandas.DataFrame.drop_duplicates method\n",
    "missing_traindf = train_df.isna().sum()\n",
    "missing_testdf = test_df.isna().sum()\n",
    "print(missing_traindf, missing_testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbgtkOAPqQ6C"
   },
   "source": [
    "### Insights:\n",
    "\n",
    "\n",
    "\n",
    "*   There are no duplicated rows in both the train and test datasets\n",
    "*   Again, there are no missing values in both datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61hCe-3Sq1Tk"
   },
   "source": [
    "## Features Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_x47OLHqj0m"
   },
   "outputs": [],
   "source": [
    "# From sklearn.preprocessing use LabelEncoder to encode the categorical features.\n",
    "def encode_target_variable(data, target_variable):\n",
    "    # Encode the target variable using LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_target = label_encoder.fit_transform(data[target_variable])\n",
    "    target_encoded = pd.DataFrame(encoded_target, columns=[target_variable])\n",
    "\n",
    "    # Combine the features and the encoded target variable\n",
    "    data_encoded = pd.concat([data.iloc[:, :-1], target_encoded], axis=1)\n",
    "    data_encoded.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "    return data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_ShZ1Z8sMhI",
    "outputId": "11f1123e-8d0c-4c83-86ca-a8863dc76563"
   },
   "outputs": [],
   "source": [
    "# Encode target variable in train data\n",
    "train_df_encoded = encode_target_variable(train_df, 'Sepssis')\n",
    "\n",
    "# Print the encoded train data\n",
    "print(train_df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEL7qiis0DI8"
   },
   "source": [
    "## Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4g514DNd0CBB",
    "outputId": "61c9c99d-6d0c-4bf4-c4b0-981aa50d83dd"
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size, random_state=42, stratify=None):\n",
    "    # Split the data into train and validation sets\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=stratify)\n",
    "\n",
    "    return X_train, X_eval, y_train, y_eval\n",
    "\n",
    "# Split the data into train and validation sets for both X and y\n",
    "X_train, X_eval, y_train, y_eval = split_data(train_df_encoded.iloc[:, :-1], train_df_encoded.iloc[:, -1:], test_size=0.2, random_state=42, stratify=train_df_encoded.iloc[:, -1:])\n",
    "\n",
    "# Print the shapes of the train and validation sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_eval shape:\", X_eval.shape)\n",
    "print(\"y_eval shape:\", y_eval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bb5-9se3Jne"
   },
   "source": [
    "## Features Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BX9fJy4K1Lbm"
   },
   "outputs": [],
   "source": [
    "scaler  = StandardScaler()\n",
    "\n",
    "#Applying Scaler on the training set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "#Applying the scaler on the evaluation set\n",
    "X_eval_scaled = scaler.transform(X_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-x9uarB5IzJ"
   },
   "source": [
    "## Optional: Train Dataset Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "BiCy8S4u5LWN",
    "outputId": "fc563176-6a49-4bc6-f448-f06d823209f5"
   },
   "outputs": [],
   "source": [
    "class_counts = y_train.value_counts()\n",
    "class_counts.index =['O','1']\n",
    "\n",
    "class_colors = ['green','red']\n",
    "\n",
    "# Create a bar plot\n",
    "ax = class_counts.plot(kind='bar',color = class_colors)\n",
    "plt.title('Class Imbalance', fontsize=11, fontweight='bold')\n",
    "plt.xlabel('Class', fontsize=9)\n",
    "plt.ylabel('Count', fontsize=9)\n",
    "\n",
    "#Rotate the labels on the x_axis\n",
    "ax.set_xticklabels(class_counts.index, rotation= 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0kjMg_B9Ff-"
   },
   "source": [
    "Clearly, there's an imbalance in the dataset. The best strategy is to oversample the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-d_n-F_x-POH",
    "outputId": "973e4aca-22fb-4ae7-8c50-befb36d2dbec"
   },
   "outputs": [],
   "source": [
    "# Use Over-sampling/Under-sampling methods, more details here: https://imbalanced-learn.org/stable/install.html\n",
    "oversample= SMOTE()\n",
    "X_train_resampled,y_train_resampled= oversample.fit_resample(X_train_scaled, y_train)\n",
    "X_train_resampled.shape,y_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7wTRS05_Msg",
    "outputId": "9141bf7e-0576-4ec1-c99b-ee44de7235f9"
   },
   "outputs": [],
   "source": [
    "#Checking to see if the tarhet variables are balanced\n",
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d92Veyq3_d0V"
   },
   "source": [
    "The target variables are balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Nc6zDBT445l"
   },
   "source": [
    "# Machine Learning Modeling\n",
    "Here is the section to **build**, **train**, **evaluate** and **compare** the models to each others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XA5JzwCAycr"
   },
   "source": [
    "## Simple Model #001 logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "BCUvLRmY452b",
    "outputId": "eb1d3f68-b76e-46e7-daa0-0afbe5676664"
   },
   "outputs": [],
   "source": [
    "#Instantiating the model\n",
    "lr_model = LogisticRegression(random_state = 42)\n",
    "\n",
    "#Training the model\n",
    "lr_model.fit(X_train_resampled,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKDYPgC_Cdlt"
   },
   "outputs": [],
   "source": [
    "#Predictions on evaluation set\n",
    "lr_model_preds = lr_model.predict(X_eval_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "lr_f1_score = f1_score(y_eval, lr_model_preds)\n",
    "lr_recall = recall_score(y_eval, lr_model_preds)\n",
    "lr_precision = precision_score(y_eval, lr_model_preds)\n",
    "lr_f2_score = fbeta_score(y_eval, lr_model_preds, beta=2)\n",
    "lr_accuracy = accuracy_score(y_eval, lr_model_preds)\n",
    "\n",
    "# Calculate AUC score\n",
    "lr_auc_score = roc_auc_score(y_eval, lr_model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMvsdawkGVlL",
    "outputId": "ec84e233-4dd5-41d8-c209-ea5c0c614086"
   },
   "outputs": [],
   "source": [
    "print(\"F1 Score:\", lr_f1_score)\n",
    "print(\"Recall Score:\", lr_recall)\n",
    "print(\"Precision Score:\", lr_precision)\n",
    "print(\"F2 Score:\", lr_f2_score)\n",
    "print(\"Accuracy Score:\", lr_accuracy)\n",
    "print(\"ROC AUC Score:\", lr_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvo3gL4HVXKz"
   },
   "source": [
    "## Simple Model #002 Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "A_EN0zDcVYg7",
    "outputId": "ea7bab64-9513-420a-807d-cf50ad87533a"
   },
   "outputs": [],
   "source": [
    "#Instantiating the model\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "#Training Model\n",
    "tree_classifier.fit(X_train_resampled,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzYAFIXAWtqV"
   },
   "outputs": [],
   "source": [
    "#Predictions on Evaluation set\n",
    "tree_classifier_preds = tree_classifier.predict(X_eval_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "tree_classifier_f1_score = f1_score(y_eval, tree_classifier_preds)\n",
    "tree_classifier_recall = recall_score(y_eval, tree_classifier_preds)\n",
    "tree_classifier_precision = precision_score(y_eval, tree_classifier_preds)\n",
    "tree_classifier_f2_score = fbeta_score(y_eval, tree_classifier_preds, beta=2)\n",
    "tree_classifier_accuracy = accuracy_score(y_eval, tree_classifier_preds)\n",
    "\n",
    "# Calculate AUC score\n",
    "tree_classifier_auc_score = roc_auc_score(y_eval, tree_classifier_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WgZBiSiXti7",
    "outputId": "7c2affd5-1b9f-4011-8b83-7b558ded45b5"
   },
   "outputs": [],
   "source": [
    "print(\"F1 Score:\", tree_classifier_f1_score)\n",
    "print(\"Recall Score:\", tree_classifier_recall)\n",
    "print(\"Precision Score:\", tree_classifier_precision)\n",
    "print(\"F2 Score:\", tree_classifier_f2_score)\n",
    "print(\"Accuracy Score:\", tree_classifier_accuracy)\n",
    "print(\"ROC AUC Score:\", tree_classifier_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_uoIRXWYbdX"
   },
   "source": [
    "## Simple Model #003 - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "OFUt0CpRYcw6",
    "outputId": "07cef443-9da7-4a67-8d6a-3d69c830b945"
   },
   "outputs": [],
   "source": [
    "#Instantiating the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 10000)\n",
    "\n",
    "#Training Model\n",
    "rf_classifier.fit(X_train_resampled,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7fH9SCpYjUv"
   },
   "outputs": [],
   "source": [
    "#Predictions on Evaluation set\n",
    "rf_classifier_preds = rf_classifier.predict(X_eval_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rf_classifier_f1_score = f1_score(y_eval, rf_classifier_preds)\n",
    "rf_classifier_recall = recall_score(y_eval, rf_classifier_preds)\n",
    "rf_classifier_precision = precision_score(y_eval, rf_classifier_preds)\n",
    "rf_classifier_f2_score = fbeta_score(y_eval, rf_classifier_preds, beta=2)\n",
    "rf_classifier_accuracy = accuracy_score(y_eval, rf_classifier_preds)\n",
    "\n",
    "# Calculate AUC score\n",
    "rf_classifier_auc_score = roc_auc_score(y_eval, rf_classifier_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9Tjvrt1YkgO",
    "outputId": "da346354-226e-437d-a973-792936d6d8ff"
   },
   "outputs": [],
   "source": [
    "print(\"F1 Score:\", rf_classifier_f1_score)\n",
    "print(\"Recall Score:\", rf_classifier_recall)\n",
    "print(\"Precision Score:\", rf_classifier_precision)\n",
    "print(\"F2 Score:\", rf_classifier_f2_score)\n",
    "print(\"Accuracy Score:\", rf_classifier_accuracy)\n",
    "print(\"ROC AUC Score:\", rf_classifier_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OM5aWTgbLPH"
   },
   "source": [
    "## Simple Model #004 - XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "UdDkHVBobRUl",
    "outputId": "c7b31898-7195-4420-8cd6-f49f66b545c9"
   },
   "outputs": [],
   "source": [
    "#Instantiating the model\n",
    "xgb_classifier = XGBClassifier(n_estimators =10000)\n",
    "\n",
    "#Training Model\n",
    "xgb_classifier.fit(X_train_resampled,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRWZXGUtbVVd"
   },
   "outputs": [],
   "source": [
    "#Predictions on Evaluation set\n",
    "xgb_classifier_preds = xgb_classifier.predict(X_eval_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "xgb_classifier_f1_score = f1_score(y_eval, xgb_classifier_preds)\n",
    "xgb_classifier_recall = recall_score(y_eval, xgb_classifier_preds)\n",
    "xgb_classifier_precision = precision_score(y_eval, xgb_classifier_preds)\n",
    "xgb_classifier_f2_score = fbeta_score(y_eval, xgb_classifier_preds, beta=2)\n",
    "xgb_classifier_accuracy = accuracy_score(y_eval, xgb_classifier_preds)\n",
    "\n",
    "# Calculate AUC score\n",
    "xgb_classifier_auc_score = roc_auc_score(y_eval, xgb_classifier_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKEnnkxVbYRD",
    "outputId": "0fe05cb8-921c-4dab-8436-492e56a6b15d"
   },
   "outputs": [],
   "source": [
    "print(\"F1 Score:\", xgb_classifier_f1_score)\n",
    "print(\"Recall Score:\", xgb_classifier_recall)\n",
    "print(\"Precision Score:\", xgb_classifier_precision)\n",
    "print(\"F2 Score:\", xgb_classifier_f2_score)\n",
    "print(\"Accuracy Score:\", xgb_classifier_accuracy)\n",
    "print(\"ROC AUC Score:\", xgb_classifier_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJLsx3DmeSeY"
   },
   "source": [
    "## Simple Model #005 - Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "ZYgYzThMeaJG",
    "outputId": "da765405-697f-4543-d3be-8bff7c10630d"
   },
   "outputs": [],
   "source": [
    "#Instantiating the model\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "#Training Model\n",
    "nb_classifier.fit(X_train_resampled,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXMmYjTse6tn"
   },
   "outputs": [],
   "source": [
    "#Predictions on Evaluation set\n",
    "nb_classifier_preds = nb_classifier.predict(X_eval_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "nb_classifier_f1_score = f1_score(y_eval, nb_classifier_preds)\n",
    "nb_classifier_recall = recall_score(y_eval, nb_classifier_preds)\n",
    "nb_classifier_precision = precision_score(y_eval, nb_classifier_preds)\n",
    "nb_classifier_f2_score = fbeta_score(y_eval, nb_classifier_preds, beta=2)\n",
    "nb_classifier_accuracy = accuracy_score(y_eval, nb_classifier_preds)\n",
    "\n",
    "# Calculate AUC score\n",
    "nb_classifier_auc_score = roc_auc_score(y_eval, nb_classifier_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qxo7kWH_e-Kw",
    "outputId": "7dfa93cd-9d16-4aeb-d9c4-bf9bf8c39f01"
   },
   "outputs": [],
   "source": [
    "print(\"F1 Score:\", nb_classifier_f1_score)\n",
    "print(\"Recall Score:\", nb_classifier_recall)\n",
    "print(\"Precision Score:\", nb_classifier_precision)\n",
    "print(\"F2 Score:\", nb_classifier_f2_score)\n",
    "print(\"Accuracy Score:\", nb_classifier_accuracy)\n",
    "print(\"ROC AUC Score:\", nb_classifier_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbFS3nnngg2b"
   },
   "source": [
    "## Simple Model #006 - Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "SusM_eWLgznr",
    "outputId": "9deb1a3b-d635-4d98-acc3-5d36863c2c0e"
   },
   "outputs": [],
   "source": [
    "#Instantiating the model\n",
    "sgd_classifier = SGDClassifier()\n",
    "\n",
    "#Training Model\n",
    "sgd_classifier.fit(X_train_resampled,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foZJtezvhbv_"
   },
   "outputs": [],
   "source": [
    "#Predictions on Evaluation set\n",
    "sgd_classifier_preds = sgd_classifier.predict(X_eval_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "sgd_classifier_f1_score = f1_score(y_eval, sgd_classifier_preds)\n",
    "sgd_classifier_recall = recall_score(y_eval, sgd_classifier_preds)\n",
    "sgd_classifier_precision = precision_score(y_eval, sgd_classifier_preds)\n",
    "sgd_classifier_f2_score = fbeta_score(y_eval, sgd_classifier_preds, beta=2)\n",
    "sgd_classifier_accuracy = accuracy_score(y_eval, sgd_classifier_preds)\n",
    "\n",
    "# Calculate AUC score\n",
    "sgd_classifier_auc_score = roc_auc_score(y_eval, sgd_classifier_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwsxsOeaheqD",
    "outputId": "1e905388-ea9c-464a-c792-2cb6d9bb7935"
   },
   "outputs": [],
   "source": [
    "print(\"F1 Score:\", sgd_classifier_f1_score)\n",
    "print(\"Recall Score:\", sgd_classifier_recall)\n",
    "print(\"Precision Score:\", sgd_classifier_precision)\n",
    "print(\"F2 Score:\", sgd_classifier_f2_score)\n",
    "print(\"Accuracy Score:\", sgd_classifier_accuracy)\n",
    "print(\"ROC AUC Score:\", sgd_classifier_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8rjb-Y3jOfR"
   },
   "source": [
    "## Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-8m_TnCjP-p"
   },
   "outputs": [],
   "source": [
    "results = {'model': ['Logistic Regression','Decision Tree', 'Random Forest','XGBoost','Naive Bayes','Stochastic Gradient Descent'],\n",
    "           'f1_score': [lr_f1_score, tree_classifier_f1_score,rf_classifier_f1_score,xgb_classifier_f1_score,nb_classifier_f1_score,sgd_classifier_f1_score],\n",
    "           'Details': ['','','','','','']}\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "NoVGUE1WmeXU",
    "outputId": "f915f4f8-166a-4c32-e131-79625e8e92f0"
   },
   "outputs": [],
   "source": [
    "results_df.sort_values(by = 'f1_score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkWHCMIR1WFJ"
   },
   "source": [
    "The best performing models are the Logistic Regression Model, Random_Forest and Naive Bayes and XGB model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkfT6eCUm6PP"
   },
   "source": [
    "## Hyperparameters tuning\n",
    "\n",
    "Fine-tune the Top-k models (3 < k < 5) using a ` GridSearchCV`  (that is in sklearn.model_selection\n",
    ") to find the best hyperparameters and achieve the maximum performance of each of the Top-k models, then compare them again to select the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZtdp4sl2Xs9"
   },
   "source": [
    "###### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1YabvCQm7WN"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "        'C': [10, 30, 50, 70, 80, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [10, 20, 30, 40, 50]\n",
    "    }\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "        'F1': 'f1',\n",
    "        'ROC AUC': 'roc_auc'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dargsaBf6Nzx"
   },
   "outputs": [],
   "source": [
    "# Perform grid search to find the best hyperparameters\n",
    "lr_grid_search = GridSearchCV(estimator = lr_model, param_grid = param_grid, scoring=scoring, cv=5, refit='F1')\n",
    "lr_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "lr_tuned_results = {\n",
    "        'best_params': lr_grid_search.best_params_,\n",
    "        'best_estimator': lr_grid_search.best_estimator_,\n",
    "        'best_f1_score': lr_grid_search.best_score_,\n",
    "        'best_roc_auc_score': roc_auc_score(y_train_resampled, lr_grid_search.predict_proba(X_train_resampled)[:, 1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EnmkR27W6TGe",
    "outputId": "af1c47f8-429b-4b3b-b786-19439cdade81"
   },
   "outputs": [],
   "source": [
    "lr_tuned_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCzEVRR098X1"
   },
   "source": [
    "##### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYFIrwkpOPff"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "        'n_estimators': [100,1000],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2,5,4],\n",
    "        'min_samples_leaf': [1,2,4] ,\n",
    "        'max_features':['auto','sqrt','log2']\n",
    "    }\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "        'F1': 'f1',\n",
    "        'ROC AUC': 'roc_auc'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3Z7BYpzOZeb"
   },
   "outputs": [],
   "source": [
    "# Perform grid search to find the best hyperparameters\n",
    "rf_grid_search = GridSearchCV(estimator = rf_classifier, param_grid = param_grid, scoring=scoring, cv=5, refit='F1')\n",
    "rf_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "rf_tuned_results = {\n",
    "        'best_params': rf_grid_search.best_params_,\n",
    "        'best_estimator': rf_grid_search.best_estimator_,\n",
    "        'best_f1_score': rf_grid_search.best_score_,\n",
    "        'best_roc_auc_score': roc_auc_score(y_train_resampled, rf_grid_search.predict_proba(X_train_resampled)[:, 1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsQHRKlkOcyd",
    "outputId": "f38bcd85-7dc1-4167-c7c6-0e34e8aca80d"
   },
   "outputs": [],
   "source": [
    "rf_tuned_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MU8NH1DjP6kT"
   },
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rG69tHhNQCWk"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'priors': [None, [0.1, 0.3, 0.6]],\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "}\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "        'F1': 'f1',\n",
    "        'ROC AUC': 'roc_auc'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCU2OXaQQHKv"
   },
   "outputs": [],
   "source": [
    "# Perform grid search to find the best hyperparameters\n",
    "nb_grid_search = GridSearchCV(estimator = nb_classifier, param_grid = param_grid, scoring=scoring, cv=5, refit='F1')\n",
    "nb_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "nb_tuned_results = {\n",
    "        'best_params': nb_grid_search.best_params_,\n",
    "        'best_estimator': nb_grid_search.best_estimator_,\n",
    "        'best_f1_score': nb_grid_search.best_score_,\n",
    "        'best_roc_auc_score': roc_auc_score(y_train_resampled, nb_grid_search.predict_proba(X_train_resampled)[:, 1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0Wj-rWLQLjq",
    "outputId": "af3d1d66-86c0-41ac-8f40-bc9ceecd5ae5"
   },
   "outputs": [],
   "source": [
    "nb_tuned_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iV_Ugut_RN91"
   },
   "source": [
    "#### XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXWsVKf9RcEX"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "        'F1': 'f1',\n",
    "        'ROC AUC': 'roc_auc'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rv3QfWw4R85M"
   },
   "outputs": [],
   "source": [
    "# Perform grid search to find the best hyperparameters\n",
    "xgb_grid_search = GridSearchCV(estimator = xgb_classifier, param_grid = param_grid, scoring=scoring, cv=5, refit='F1')\n",
    "xgb_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "xgb_tuned_results = {\n",
    "        'best_params': xgb_grid_search.best_params_,\n",
    "        'best_estimator': xgb_grid_search.best_estimator_,\n",
    "        'best_f1_score': xgb_grid_search.best_score_,\n",
    "        'best_roc_auc_score': roc_auc_score(y_train_resampled, nb_grid_search.predict_proba(X_train_resampled)[:, 1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0ViIg2yXpSy",
    "outputId": "cc9b32ff-8970-4865-827c-7759c06ae0c9"
   },
   "outputs": [],
   "source": [
    "xgb_tuned_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_9QMc9ZZo4G"
   },
   "source": [
    "## Hyperparameter tuning results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "NEX4qZ8vZoF0",
    "outputId": "07e398ed-f6f5-46ad-a343-4cf8ed1916bc"
   },
   "outputs": [],
   "source": [
    "\n",
    "results_new= {'model':['Logistic_Regression','Random Forest','SGD Classifier','XGB Classifier'],\n",
    "         'f1_score':[lr_tuned_results['best_f1_score'],rf_tuned_results['best_f1_score'],nb_tuned_results['best_f1_score'],xgb_tuned_results['best_f1_score']],\n",
    "         'AUC_score':[lr_tuned_results['best_roc_auc_score'],rf_tuned_results['best_roc_auc_score'],nb_tuned_results['best_roc_auc_score'],xgb_tuned_results['best_roc_auc_score']]}\n",
    "\n",
    "results_new_df= pd.DataFrame(results_new)\n",
    "\n",
    "results_new_df.sort_values(by= 'f1_score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30EgehL1gxMU"
   },
   "source": [
    "From the table above , the best performing model is the Random Forest Classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoaHO5afhOVo"
   },
   "source": [
    "### Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "uThbPOzohEQn",
    "outputId": "2cc38ecf-36b7-40b2-bf5c-76520c0878ef"
   },
   "outputs": [],
   "source": [
    "model = rf_tuned_results['best_estimator']\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-4WUBIohnpw"
   },
   "outputs": [],
   "source": [
    "#Preprocessing  the test_data\n",
    "X_test_new = test_df.drop('ID', axis =1)\n",
    "X_test_scaled = scaler.transform(X_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Y9uQ2XriLqw",
    "outputId": "990b7d93-20d7-4108-9402-bd87293429db"
   },
   "outputs": [],
   "source": [
    "#Running Predictions on the test data\n",
    "test_preds = model.predict(X_test_scaled)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nUW_uPnmwx7"
   },
   "outputs": [],
   "source": [
    "#Saving Test Presdictions\n",
    "test_predictions = pd.DataFrame(test_preds, columns = ['Sepsis'])\n",
    "test_predictions.to_csv('test_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NF3W3txGnqDX"
   },
   "source": [
    "# Export Key Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPuVcDYzoDh5",
    "outputId": "e296181b-869f-4948-fa44-117a16d3d911"
   },
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Specify the relative path to the destination directory\n",
    "destination = os.path.join(cwd, \"Assets\")\n",
    "\n",
    "# Create the \"export\" directory if it doesn't exist\n",
    "os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "# Export the scaler\n",
    "scaler_filepath = os.path.join(destination, \"scaler.joblib\")\n",
    "dump(scaler, scaler_filepath)\n",
    "\n",
    "# Export the random forest classifier\n",
    "model_filepath = os.path.join(destination, \"model.joblib\")\n",
    "dump(model, model_filepath)\n",
    "\n",
    "# Print the paths to the exported components\n",
    "print(f\"Scaler exported to: {scaler_filepath}\")\n",
    "print(f\"Random Classifier exported to: {model_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVyQpj25pxET"
   },
   "outputs": [],
   "source": [
    "#Exporting all libraries\n",
    "!pip list --format=freeze >Assets/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOl/kAndgJqTj1vWa6WlUG3",
   "include_colab_link": true,
   "mount_file_id": "10y3dWcMvnhycrPs0pqTIqWnlWA2eqgOV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
